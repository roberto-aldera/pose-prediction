{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "torch.manual_seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 2\n",
    "num_frames = 2\n",
    "input_size = num_features * num_frames\n",
    "output_size = num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the artificial dataset\n",
    "dim1_data = np.arange(0,5.2,0.1)\n",
    "dim2_data = np.arange(0,0.52,0.01)\n",
    "\n",
    "# dim1_data = np.linspace(0,3,52)\n",
    "# dim2_data = np.linspace(0,0.3,52)\n",
    "\n",
    "dim1_data_scaled = (dim1_data - dim1_data.mean())/dim1_data.std()\n",
    "dim2_data_scaled = (dim2_data - dim2_data.mean())/dim2_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data2d(Dataset):   \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        x_data = torch.tensor(dim1_data_scaled)\n",
    "        y_data = torch.tensor(dim2_data_scaled)\n",
    "        \n",
    "        self.x = torch.zeros(len(dim1_data)-num_frames,input_size)\n",
    "        self.x[:,3] = y_data[:-2]\n",
    "        self.x[:,2] = x_data[:-2]\n",
    "        self.x[:,1] = y_data[1:-1]\n",
    "        self.x[:,0] = x_data[1:-1]\n",
    "        \n",
    "        self.y = torch.zeros(len(dim1_data)-num_frames,output_size)\n",
    "        self.y[:,0] = x_data[2:]\n",
    "        self.y[:,1] = y_data[2:]\n",
    "        \n",
    "        self.len = self.x.shape[0]\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Getting the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "# Instantiation of the class  \n",
    "my_data = Data2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  OrderedDict([('linear.weight', tensor([[ 0.2576, -0.2207, -0.0969,  0.2347],\n",
      "        [-0.4707,  0.2999, -0.1029,  0.2544]])), ('linear.bias', tensor([ 0.0695, -0.0612]))])\n"
     ]
    }
   ],
   "source": [
    "# Creating a linear regression model\n",
    "class lin_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(lin_reg, self).__init__()\n",
    "        self.linear = nn.Linear(in_feat, out_feat)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "    \n",
    "# Instantiation of an object\n",
    "model = lin_reg(input_size,output_size)\n",
    "print(\"The parameters: \", model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01) \n",
    "# Training data object which loads the artificial data\n",
    "trainloader = DataLoader(dataset = my_data, batch_size = 1)\n",
    "# Training the model\n",
    "Loss = []  # variable for storing losses after each epoch\n",
    "epochs = 50\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for x,y in trainloader:\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat,y)\n",
    "            Loss.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "# Calling the training function          \n",
    "train_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d956f4410>]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASdElEQVR4nO3db4xc1X3G8eeZXXsXYxvjeCHGNixQqoi0pHEXQps2TV4EsNvGrZoqoKr8SailCNREal9AIwHNu1QqaSkI5DQOEEUQiaSNKzkC8qeiUQVhQcZgLMcLIWJjN17jYNY27HrXv76YO7tzZ+7uju1Zz56Z70dazZ17z86cM3f8+Oy5597riBAAIH2lVlcAANAcBDoAtAkCHQDaBIEOAG2CQAeANtHdqjdetWpV9Pf3t+rtASBJL7zwwsGI6Cva1rJA7+/v1+DgYKveHgCSZPsXM21jyAUA2gSBDgBtgkAHgDZBoANAmyDQAaBNEOgA0CYIdABoE8kF+p7/G9W9T+3RwSNjra4KACwoyQX63gOjuu9HQzp0dLzVVQGABSW5QLfc6ioAwIKUXKBXcKMlAMibM9Btr7P9Y9u7be+y/YWCMrZ9n+0h2zttr5+f6krOOughEh0AqjVyca4JSX8XES/aXibpBdtPR8SrVWU2SLos+/mIpAezx6arDLjQQweAvDl76BGxPyJezJZHJe2WtKam2CZJj0bZs5JW2F7d9NpquocOAMg7qTF02/2SPizpuZpNayS9WfV8WPWhL9ubbQ/aHhwZGTm5mtaghw4AeQ0Huu2lkr4j6YsR8U7t5oJfqYvciNgSEQMRMdDXV3h99kZqkr04iQ4A1RoKdNuLVA7zb0XEdwuKDEtaV/V8raR9p1+9orqUH+mhA0BeI7NcLOnrknZHxL0zFNsm6cZstsvVkg5HxP4m1nO6PvPxogDQBhqZ5fJRSX8t6WXbO7J1/yDpQkmKiIckbZe0UdKQpGOSbml+VQEAs5kz0CPiJ5qjYxwRIem2ZlVqNs7GXBhyAYC85M4UnZqHzkFRAMhJL9AZRAeAQskFegVDLgCQl1ygT1/LBQBQLb1Ar5xYRBcdAHKSC3QmogNAsfQCPUP/HADykgt0Lp8LAMXSC3RPz0QHAExLL9BbXQEAWKCSC/QKhlwAIC+5QGceOgAUSy/QxcW5AKBIeoHOIDoAFEou0Cs4UxQA8pILdCYtAkCx5AJd3FMUAAolF+hmJjoAFEou0Cu4YxEA5CUX6Jz5DwDF0gv07JE8B4C89ALdnFgEAEUSDPRW1wAAFqbkAr2Cg6IAkJdcoHODCwAoll6gc7VFACiUXKBziwsAKJZgoJdxcS4AyEsu0BlyAYBi6QV6ZYFEB4Cc9AKdiegAUCi5QK9gHjoA5CUX6MxDB4Bi6QU6N7gAgELpBTrz0AGgUHKBXkEHHQDykgv06SEXIh0AqiUX6BXEOQDkJRfoTEMHgGJzBrrtrbYP2H5lhu0ft33Y9o7s567mV7MeIy4AkNfdQJmHJd0v6dFZyvxPRPxJU2o0B3NXUQAoNGcPPSKekXToDNSlIcxDB4BizRpD/z3bL9n+vu0PzlTI9mbbg7YHR0ZGTumNGEMHgGLNCPQXJV0UER+S9G+S/nOmghGxJSIGImKgr6/vtN6UDjoA5J12oEfEOxFxJFveLmmR7VWnXbMZVMbQGXIBgLzTDnTb73d2TVvbV2Wv+dbpvu7M71d+5GqLAJA35ywX249J+rikVbaHJd0taZEkRcRDkj4t6fO2JyS9K+n6mMfTOBlCB4BicwZ6RNwwx/b7VZ7WeEYx5AIAecmeKUqeA0BecoGuqYOiRDoAVEsu0JmHDgDFkgt0AECx5AKde4oCQLH0Aj0bc2EeOgDkpRfora4AACxQyQV6BUMuAJCXXKBz+VwAKJZeoFfmobe4HgCw0KQX6AyiA0Ch5AK9gjNFASAv3UBvdQUAYIFJLtDNPaIBoFCCgc4gOgAUSS7QKzhTFADykgt0ruUCAMXSC3RucAEAhdILdK7mAgCFkgv0CoZcACAvuUCfHnIh0QGgWnqBnj3SQweAvOQCnSF0ACiWXqBn6KADQF5ygT41y4UxFwDISS/QmYcOAIXSC/RWVwAAFqjkAr2CERcAyEsu0CtXW+QGFwCQl16gZ4/EOQDkpRfoDKIDQKHkAr2CERcAyEsu0Cvz0MlzAMhLLtCnzysi0gGgWnKBzhg6ABRLLtABAMWSC3QunwsAxdIL9MqJRRwWBYCc9AK91RUAgAVqzkC3vdX2AduvzLDdtu+zPWR7p+31za9mPYZcACCvkR76w5Kum2X7BkmXZT+bJT14+tWaGZfPBYBicwZ6RDwj6dAsRTZJejTKnpW0wvbqZlWw1tSJRSQ6AOQ0Ywx9jaQ3q54PZ+vq2N5se9D24MjIyCm92XQPnUQHgGrNCPSi45SFaRsRWyJiICIG+vr6mvDWAICKZgT6sKR1Vc/XStrXhNedFUMuAJDXjEDfJunGbLbL1ZIOR8T+JrxuIU79B4Bi3XMVsP2YpI9LWmV7WNLdkhZJUkQ8JGm7pI2ShiQdk3TLfFVWqj4oShcdAKrNGegRccMc20PSbU2r0RzooQNAseTOFK2ggw4AeckFOvcUBYBi6QW6ObEIAIqkF+itrgAALFDJBXoFZ4oCQF5ygT516j95DgA5CQZ65QYXAIBqyQU6AKBYuoHOmAsA5CQZ6DZDLgBQK81AFx10AKiVZqBzQRcAqJNkoEvMQweAWkkGOkMuAFAvzUDnoCgA1Ekz0LmiCwDUSTLQJYZcAKBWmoFuDooCQK0kA71keugAUCvJQO+ydeIEiQ4A1ZIM9JIt8hwA8pIMdFs6wZgLAOQkGeilkhUEOgDkpBnoDLkAQJ1EA50hFwColWSg2ybQAaBGkoFenrbY6loAwMKSZKAz5AIA9ZIMdHNQFADqJBnopZKYtggANdIMdA6KAkCdhAO91bUAgIUlyUC3pUl66ACQk2Sgl8yp/wBQK8lAZx46ANRLMtC52iIA1Esy0DkoCgD10gx05qEDQJ00A5156ABQp6FAt32d7T22h2zfUbD9ZtsjtndkP7c2v6q592PIBQBqdM9VwHaXpAckfVLSsKTnbW+LiFdrin47Im6fhzrW4eJcAFCvkR76VZKGIuL1iBiX9LikTfNbrdl1MeQCAHUaCfQ1kt6sej6crav1F7Z32n7C9rqiF7K92fag7cGRkZFTqG5ZiXnoAFCnkUB3wbra7vF/SeqPiCsk/UDSI0UvFBFbImIgIgb6+vpOrqbVFWLIBQDqNBLow5Kqe9xrJe2rLhARb0XEWPb0a5J+tznVK1Y+9X8+3wEA0tNIoD8v6TLbF9teLOl6SduqC9heXfX0U5J2N6+K9UoleugAUGvOWS4RMWH7dklPSuqStDUidtn+sqTBiNgm6W9tf0rShKRDkm6exzozDx0ACswZ6JIUEdslba9Zd1fV8p2S7mxu1WZmW5PkOQDkJHqmKKf+A0CtJAOdeegAUC/JQDfz0AGgTpKBzqn/AFAv0UBnHjoA1Eoz0JmHDgB1kgx0c1AUAOokGejcgg4A6iUZ6F0cFAWAOkkGOqf+A0C9JAOdeegAUC/JQOfUfwCol2igc1AUAGqlGegla4JEB4CcJAN9cZc1wSA6AOQkGejdXSUdnyDQAaBakoG+qKuk4wy5AEBOooFuHZ+khw4A1RIN9JIipEl66QAwJclA7+6yJE310iNCo+8db2WVAKDlkgz0xV3lalcC/V9+sFdX/ONTOnR0vJXVAoCWSjLQu0uVHnp5yOVff7hXEdKufYdbWS0AaKk0Az3roU9kPfRlvd2SpDcOHm1ZnQCg1ZIM9MqQy/jUGHp5/cEjDLkA6FxJBnrloOjEZGhsYlJHxiYkSW8dHWtltQCgpZIM9EVVB0XfquqVHxylhw6gcyUa6NMHRUdGp3vl9NABdLJEA326h37wSDnELzinV28fYy46gM6VZKBPzXI5cWKqh37peUv19rsEOoDOlWSgV4Zcxidiqod+ad9SHX73OHcyAtCxkgz0nu7paYsHj4xrWW+3zl/eq/GJE3rvOBftAtCZkgz0JYvLJxIdG5vQyOiY+pb1aMWSRZKkt99lpguAzpRkoC/tKQf6kbEJjRwZ06qlPepdVG4KPXQAnSrJQF+yuEuSdHRsQgezHnpXqdwULqkLoFMlGehnZz30o+OT5SGXpT3qcvlAKYEOoFMlGeg93SV1l6yR0TGNjk3o/OW96ioR6AA6W5KBbltLFnfp9ezqiucv7yHQAXS8JANdKh8Yfe3AEUnS+5f3Tl0jfZJ56AA6VLKB3re8V798+11J0nnLe1Wihw6gwzUU6Lavs73H9pDtOwq299j+drb9Odv9za5orQvO6c3eW1qz4qzpHnoW6IeOjuuzDz+va7/6jF4bOTLf1QGAlpsz0G13SXpA0gZJl0u6wfblNcU+J+nXEfEbkr4q6SvNrmitC1acJUm6aOUSnbW4a2oM/dj4hHYOv61ND/xEz/xsRHsPjOpvHhnU0bEJTUye0OsjR/Tfew7of4cOavQ9LhUAoH10N1DmKklDEfG6JNl+XNImSa9Wldkk6Z5s+QlJ99t2zGNaXrH2HEnSb69dIUm6/ILlWtbTrVsfGdTEidD5y3v0xOd/X0fHJvRX//6cPnj3k7Kn725Usay3W0sWd6lky+X2ydZU2QjpRPZLtdurf6fCquHCxdzvdDI+BXSiz1y5Trf+4SVNf91GAn2NpDerng9L+shMZSJiwvZhSe+TdLC6kO3NkjZL0oUXXniKVS7b8FurNfLHY/rTD10gSVreu0jfuOVKfW/HPl24cok+c9U6Le8tXw7gGzdfqZ++cUiLSta6lUvUv+psHRuf1PM/P6RDx8Y1ORkKhU5kAR4KReRDW5JClZCPbLn8O6raXq36/7PcNv4okFT+nIFOtGppz7y8biOBXtSJqv2X2EgZRcQWSVskaWBg4LT+NS/uLtX9DzfQv1ID/Svryn7iA+fpEx84r279H/1m3+lUAQAWlEYOig5LWlf1fK2kfTOVsd0t6RxJh5pRQQBAYxoJ9OclXWb7YtuLJV0vaVtNmW2SbsqWPy3pR/M5fg4AqDfnkEs2Jn67pCcldUnaGhG7bH9Z0mBEbJP0dUnftD2kcs/8+vmsNACgXiNj6IqI7ZK216y7q2r5PUl/2dyqAQBORrJnigIA8gh0AGgTBDoAtAkCHQDahFs1u9D2iKRfnOKvr1LNWagdgDZ3BtrcGU6nzRdFROFZkS0L9NNhezAiBlpdjzOJNncG2twZ5qvNDLkAQJsg0AGgTaQa6FtaXYEWoM2dgTZ3hnlpc5Jj6ACAeqn20AEANQh0AGgTyQX6XDesTpntN2y/bHuH7cFs3UrbT9vemz2em6237fuyz2Gn7fWtrX1jbG+1fcD2K1XrTrqNtm/Kyu+1fVPRey0UM7T5Htu/zPb1Dtsbq7bdmbV5j+1rq9Yn8d23vc72j23vtr3L9hey9W27n2dp85ndzxGRzI/Kl+99TdIlkhZLeknS5a2uVxPb94akVTXr/knSHdnyHZK+ki1vlPR9le8WdbWk51pd/wbb+DFJ6yW9cqptlLRS0uvZ47nZ8rmtbttJtvkeSX9fUPby7HvdI+ni7PveldJ3X9JqSeuz5WWSfpa1q2338yxtPqP7ObUe+tQNqyNiXFLlhtXtbJOkR7LlRyT9WdX6R6PsWUkrbK9uRQVPRkQ8o/q7WZ1sG6+V9HREHIqIX0t6WtJ181/7UzNDm2eySdLjETEWET+XNKTy9z6Z735E7I+IF7PlUUm7Vb7vcNvu51naPJN52c+pBXrRDatn+9BSE5Kesv1CdkNtSTo/IvZL5S+NpMrNUdvpszjZNrZL22/Phhi2VoYf1GZttt0v6cOSnlOH7OeaNktncD+nFugN3Yw6YR+NiPWSNki6zfbHZinb7p+FNHMb26HtD0q6VNLvSNov6Z+z9W3TZttLJX1H0hcj4p3Zihasa5c2n9H9nFqgN3LD6mRFxL7s8YCk/1D5z69fVYZSsscDWfF2+ixOto3Jtz0ifhURkxFxQtLXVN7XUpu02fYilYPtWxHx3Wx1W+/nojaf6f2cWqA3csPqJNk+2/ayyrKkayS9ovwNuG+S9L1seZukG7MZAldLOlz5czZBJ9vGJyVdY/vc7E/Ya7J1yag53vHnKu9rqdzm62332L5Y0mWSfqqEvvu2rfJ9hndHxL1Vm9p2P8/U5jO+n1t9dPgUjiZvVPkI8muSvtTq+jSxXZeofET7JUm7Km2T9D5JP5S0N3tcma23pAeyz+FlSQOtbkOD7XxM5T89j6vcG/ncqbRR0mdVPpA0JOmWVrfrFNr8zaxNO7N/sKuryn8pa/MeSRuq1ifx3Zf0ByoPE+yUtCP72djO+3mWNp/R/cyp/wDQJlIbcgEAzIBAB4A2QaADQJsg0AGgTRDoANAmCHQAaBMEOgC0if8Hj3WyxSL5kT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.2 6.1]\n",
      "[0.62 0.61]\n",
      "[2.43198261 2.36535295]\n",
      "[2.43198261 2.36535295]\n",
      "tensor([[2.4320, 2.4320, 2.3654, 2.3654]])\n",
      "\n",
      " raw answer:\n",
      " tensor([[2.4986, 2.4986]], grad_fn=<AddmmBackward>)\n",
      "\n",
      " scaled up again:\n",
      "\n",
      "tensor(6.3000, grad_fn=<AddBackward0>)\n",
      "tensor(0.6300, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "query_dim1 = np.array([6.2,6.1])\n",
    "query_dim2 = np.array([0.62,0.61])\n",
    "print(query_dim1)\n",
    "print(query_dim2)\n",
    "\n",
    "scaled_query_dim1 = (query_dim1 - dim1_data.mean())/dim1_data.std()\n",
    "scaled_query_dim2 = (query_dim2 - dim2_data.mean())/dim2_data.std()\n",
    "print(scaled_query_dim1)\n",
    "print(scaled_query_dim2)\n",
    "\n",
    "# Build combination so x and y are adjacent for 1 pose\n",
    "c = np.empty(scaled_query_dim1.size + scaled_query_dim2.size)\n",
    "c[0::2] = scaled_query_dim1\n",
    "c[1::2] = scaled_query_dim2\n",
    "\n",
    "new_query = Variable(torch.Tensor([c]))\n",
    "print(new_query)\n",
    "\n",
    "answer = model(new_query)\n",
    "print('\\n raw answer:\\n',answer)\n",
    "print('\\n scaled up again:\\n')\n",
    "print(answer[0][0]*dim1_data.std() + dim1_data.mean())\n",
    "print(answer[0][1]*dim2_data.std() + dim2_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

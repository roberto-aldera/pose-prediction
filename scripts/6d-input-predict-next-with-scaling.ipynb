{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "torch.manual_seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 3\n",
    "num_frames = 2\n",
    "input_size = num_features * num_frames\n",
    "output_size = num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the artificial dataset\n",
    "dim1_data = np.arange(0,5.2,0.1)\n",
    "dim2_data = np.arange(0,0.52,0.01)\n",
    "dim3_data = np.arange(0,0.052,0.001)\n",
    "\n",
    "dim1_data_scaled = (dim1_data - dim1_data.mean())/dim1_data.std()\n",
    "dim2_data_scaled = (dim2_data - dim2_data.mean())/dim2_data.std()\n",
    "dim3_data_scaled = (dim3_data - dim3_data.mean())/dim3_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data2d(Dataset):   \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        x_data = torch.tensor(dim1_data_scaled)\n",
    "        y_data = torch.tensor(dim2_data_scaled)\n",
    "        theta_data = torch.tensor(dim3_data_scaled)\n",
    "        \n",
    "        # input tensor holds x, y, and theta data in frame 1, frame 2\n",
    "        # [x1,y1,th1,x2,y2,th2]\n",
    "        # These are offset, so that x1 goes up until the second last frame\n",
    "        # (current frame is treated as future prediction)\n",
    "        self.x = torch.zeros(len(dim1_data)-num_frames,input_size)\n",
    "        self.x[:,5] = theta_data[:-2]\n",
    "        self.x[:,4] = y_data[:-2]\n",
    "        self.x[:,3] = x_data[:-2]\n",
    "        self.x[:,2] = theta_data[1:-1]\n",
    "        self.x[:,1] = y_data[1:-1]\n",
    "        self.x[:,0] = x_data[1:-1]\n",
    "        \n",
    "        # output tensor holds single frame, for x, y, and theta values\n",
    "        # This is cropped to exclude the first n frames (n=2 here) and run up until the end\n",
    "        # So a synthesised 'future' value to aim for\n",
    "        self.y = torch.zeros(len(dim1_data)-num_frames,output_size)\n",
    "        self.y[:,0] = x_data[2:]\n",
    "        self.y[:,1] = y_data[2:]\n",
    "        self.y[:,2] = theta_data[2:]\n",
    "        \n",
    "        self.len = self.x.shape[0]\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Getting the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "# Instantiation of the class  \n",
    "my_data = Data2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  OrderedDict([('linear.weight', tensor([[ 0.2104, -0.1802, -0.0791,  0.1916, -0.3843,  0.2448],\n",
      "        [-0.0840,  0.2077,  0.0568, -0.0500,  0.1132,  0.0201],\n",
      "        [ 0.1491, -0.1591, -0.0298, -0.0368,  0.0592, -0.0016]])), ('linear.bias', tensor([ 0.3569,  0.1270, -0.1520]))])\n"
     ]
    }
   ],
   "source": [
    "# Creating a linear regression model\n",
    "class lin_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(lin_reg, self).__init__()\n",
    "        self.linear = nn.Linear(in_feat, out_feat)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "    \n",
    "# Instantiation of an object\n",
    "model = lin_reg(input_size,output_size)\n",
    "print(\"The parameters: \", model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01) \n",
    "# Training data object which loads the artificial data\n",
    "trainloader = DataLoader(dataset = my_data, batch_size = 1)\n",
    "# Training the model\n",
    "Loss = []  # variable for storing losses after each epoch\n",
    "epochs = 50\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for x,y in trainloader:\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat,y)\n",
    "            Loss.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "# Calling the training function          \n",
    "train_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf4e30eed0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.2 6.1]\n",
      "[0.62 0.61]\n",
      "[0.062 0.061]\n",
      "[2.43198261 2.36535295]\n",
      "[2.43198261 2.36535295]\n",
      "[2.43198261 2.36535295]\n",
      "tensor([[2.4320, 2.4320, 2.4320, 2.3654, 2.3654, 2.3654]])\n",
      "\n",
      " raw answer:\n",
      " tensor([[2.4986, 2.4986, 2.4986]], grad_fn=<AddmmBackward>)\n",
      "\n",
      " scaled up again:\n",
      "\n",
      "tensor(6.3000, grad_fn=<AddBackward0>)\n",
      "tensor(0.6300, grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "query_dim1 = np.array([6.2,6.1])\n",
    "query_dim2 = np.array([0.62,0.61])\n",
    "query_dim3 = np.array([0.062,0.061])\n",
    "print(query_dim1)\n",
    "print(query_dim2)\n",
    "print(query_dim3)\n",
    "\n",
    "scaled_query_dim1 = (query_dim1 - dim1_data.mean())/dim1_data.std()\n",
    "scaled_query_dim2 = (query_dim2 - dim2_data.mean())/dim2_data.std()\n",
    "scaled_query_dim3 = (query_dim3 - dim3_data.mean())/dim3_data.std()\n",
    "print(scaled_query_dim1)\n",
    "print(scaled_query_dim2)\n",
    "print(scaled_query_dim3)\n",
    "\n",
    "# Build combination so x, y, and theta are adjacent for 1 pose\n",
    "c = np.empty(scaled_query_dim1.size + scaled_query_dim2.size + scaled_query_dim3.size)\n",
    "c[0::num_features] = scaled_query_dim1\n",
    "c[1::num_features] = scaled_query_dim2\n",
    "c[2::num_features] = scaled_query_dim3\n",
    "\n",
    "new_query = Variable(torch.Tensor([c]))\n",
    "print(new_query)\n",
    "\n",
    "answer = model(new_query)\n",
    "print('\\n raw answer:\\n',answer)\n",
    "print('\\n scaled up again:\\n')\n",
    "print(answer[0][0]*dim1_data.std() + dim1_data.mean())\n",
    "print(answer[0][1]*dim2_data.std() + dim2_data.mean())\n",
    "print(answer[0][2]*dim3_data.std() + dim3_data.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

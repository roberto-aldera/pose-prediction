{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable \n",
    "torch.manual_seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the artificial dataset\n",
    "dim1_data = np.arange(0,2.2,0.1)\n",
    "dim2_data = np.arange(0,0.22,0.01)\n",
    "\n",
    "# Find means and std devs\n",
    "# dim1_mean = dim1_data.mean()\n",
    "# dim1_std = dim1_data.std()\n",
    "\n",
    "dim1_data_scaled = (dim1_data - dim1_data.mean())/dim1_data.std()\n",
    "dim2_data_scaled = (dim2_data - dim2_data.mean())/dim2_data.std()\n",
    "\n",
    "# all_data = torch.zeros(2,1,22) # should be 3x1 for each pose, just 2x1 for now\n",
    "\n",
    "# all_data[0,0,:] = dim1_data\n",
    "# all_data[1,0,:] = dim2_data\n",
    "\n",
    "# print(all_data)\n",
    "# print(all_data.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data2d(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "#         x_data = all_data_scaled[0,0,:]\n",
    "#         y_data = all_data_scaled[1,0,:]\n",
    "        x_data = torch.tensor(dim1_data_scaled)\n",
    "        y_data = torch.tensor(dim2_data_scaled)\n",
    "        \n",
    "        self.x = torch.zeros(20,4)\n",
    "        self.x[:,3] = y_data[:-2]\n",
    "        self.x[:,2] = x_data[:-2]\n",
    "        self.x[:,1] = y_data[1:-1]\n",
    "        self.x[:,0] = x_data[1:-1]\n",
    "        \n",
    "        self.y = torch.zeros(20,2)\n",
    "        self.y[:,0] = x_data[2:]\n",
    "        self.y[:,1] = y_data[2:]\n",
    "        \n",
    "        self.len = self.x.shape[0]\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Getting the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "# Instantiation of the class  \n",
    "my_data = Data2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  OrderedDict([('linear.weight', tensor([[ 0.2576, -0.2207, -0.0969,  0.2347],\n",
      "        [-0.4707,  0.2999, -0.1029,  0.2544]])), ('linear.bias', tensor([ 0.0695, -0.0612]))])\n"
     ]
    }
   ],
   "source": [
    "# Creating a linear regression model\n",
    "class lin_reg(nn.Module):\n",
    "\n",
    "    def __init__(self, in_feat, out_feat):\n",
    "        super(lin_reg, self).__init__()\n",
    "        self.linear = nn.Linear(in_feat, out_feat)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        yhat = self.linear(x)\n",
    "        return yhat\n",
    "    \n",
    "# Instantiation of an object\n",
    "model = lin_reg(4,2)\n",
    "print(\"The parameters: \", model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01) \n",
    "# Training data object which loads the artificial data\n",
    "trainloader = DataLoader(dataset = my_data, batch_size = 1)\n",
    "# Training the model\n",
    "Loss = []  # variable for storing losses after each epoch\n",
    "epochs = 50\n",
    "\n",
    "def train_model(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for x,y in trainloader:\n",
    "            yhat = model(x)\n",
    "            loss = criterion(yhat,y)\n",
    "            Loss.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "# Calling the training function          \n",
    "train_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33f3f933d0>]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAc4UlEQVR4nO3dfZBc1Xnn8e/T3fOidyQ0ElgjWSKWMTKFg5lgvN4tQwJGkCwktXiDyknsLES7tcHJbrxJoJKFLNk/1onL9noXbKsSQtnrBWOHwipKiezwsjixwRqCjfWCYBAgDUJoJCR5NNK8dPezf9zb3bd77qhbUs+MTvfvUzXVfW9fus9Vi5/OPPfcc8zdERGR8GVmuwEiItIcCnQRkRahQBcRaREKdBGRFqFAFxFpEbnZ+uClS5f66tWrZ+vjRUSC9Pzzzx9y956012Yt0FevXk1/f/9sfbyISJDM7I2pXlPJRUSkRSjQRURahAJdRKRFKNBFRFqEAl1EpEUo0EVEWoQCXUSkRQQX6LsPDPP57+7m0PGx2W6KiMg5JbhAf+XgMF96coB3RsZnuykiIueU4ALdMAC0LoeISLXwAj3KcxwluohIUniBHj+qhy4iUi28QC/10BXoIiJV6ga6mT1gZgfNbHud437BzApmdkvzmpf6SYBKLiIitRrpoT8IrD/VAWaWBT4LbG1Cm05JPXQRkXR1A93dnwHeqXPYp4G/BQ42o1GnYvUPERFpS2ddQzezFcCvAV9p4NiNZtZvZv1DQ0Nn+nmAeugiIrWacVH0i8Afu3uh3oHuvsnd+9y9r6cndQWlusqjXFRDFxGp0owl6PqAh+Oe81LgRjPLu/tjTXjvSVRDFxFJd9aB7u5rSs/N7EHg8ekK8+gz4s+drg8QEQlU3UA3s4eAq4GlZjYI3AN0ALh73bp5s1Vu/Veki4gk1Q10d9/Q6Ju5+6fOqjWNUA9dRCRVeHeKxo/qoIuIVAsv0K0yzkVERCrCC/T4UT10EZFq4QW6augiIqnCC3QtcCEikiq8QC/fWKREFxFJCi/Q40fFuYhIteACHd36LyKSKrhANy1wISKSKrxAV81FRCRVeIEePyrPRUSqhRfoWuBCRCRVgIEePaqGLiJSLbxAjx/VQxcRqRZeoOvWfxGRVMEFOlrgQkQkVXCBrh66iEi68AK99ESJLiJSpW6gm9kDZnbQzLZP8fonzOzF+OcHZvaB5jez6vMAjXIREanVSA/9QWD9KV5/Dfiou18G/DmwqQntmpJGuYiIpGtkkehnzGz1KV7/QWLzWaD37Js1NdPkXCIiqZpdQ78N+LupXjSzjWbWb2b9Q0NDZ/QBlcm5REQkqWmBbmbXEAX6H091jLtvcvc+d+/r6ek5w88pv9cZ/fciIq2qbsmlEWZ2GfBXwA3ufrgZ71mP4lxEpNpZ99DNbBXwKPCb7v7y2Tep3udFj+qgi4hUq9tDN7OHgKuBpWY2CNwDdAC4+1eAu4HzgfvjIYV5d++brgabJtAVEUnVyCiXDXVevx24vWktqkM9dBGRdOHdKapb/0VEUoUX6GiBCxGRNOEFuha4EBFJFV6gx4/qoYuIVAsv0FVDFxFJFVyga4ELEZF0wQW6Wf1jRETaUXiBHj+qgy4iUi28QNcCFyIiqcIL9PhRPXQRkWrhBbpu/RcRSRVeoGuBCxGRVOEFuha4EBFJFVyglyjORUSqBRfopunQRURSBRjoGrYoIpImvECPH1VCFxGpFl6ga3IuEZFUdQPdzB4ws4Nmtn2K183MvmRmA2b2opl9sPnNTHyeFrgQEUnVSA/9QWD9KV6/AVgb/2wEvnz2zZpaJu6hF5XoIiJV6ga6uz8DvHOKQ24GvuaRZ4HzzOzCZjVwEpVcRERSNaOGvgLYl9gejPdNYmYbzazfzPqHhobO6MMM3fsvIpKmGYGeNkN5atq6+yZ373P3vp6enjP7MPXQRURSNSPQB4GVie1eYH8T3jeVhi2KiKRrRqBvBn4rHu1yFXDM3d9qwvumKt9YpEQXEamSq3eAmT0EXA0sNbNB4B6gA8DdvwJsAW4EBoATwG9PV2Mh0UOfzg8REQlQ3UB39w11Xnfgd5vWojqmmg/9zaMnefnAMNe8b9lMNUVE5JxSN9DPNVPNh37N555mPF/k9f/xyzPfKBGRc0Bwt/4zxXzo4/niLDRGROTcEVygW9ogSRERCTDQ40cNchERqRZeoGs+dBGRVOEFevyoHrqISLXwAl23/ouIpAov0DUfuohIqvACvdxDV6KLiCQFF+gl6qGLiFQLLtDTxqFroi4RkQADPZMy22K+qEAXEQk20JMZni8o0EVEggv0UsUluUj0RFHzuIiIhBfoKdPnTiQm5lI9XUTaVYCBbphNXUNXnotIuwou0CEquyRr6BMFlVxERIIM9IxZ1Y1FyYui6qCLSLtqKNDNbL2Z7TazATO7M+X1VWb2lJm9YGYvmtmNzW9q8vNqRrkUVUMXEakb6GaWBe4DbgDWARvMbF3NYX8KPOLulwO3Avc3u6E1baq+KKoeuohIQz30K4EBd9/j7uPAw8DNNcc4sDB+vgjY37wmTpapvSha0EVREZFGAn0FsC+xPRjvS/oz4DfMbBDYAnw67Y3MbKOZ9ZtZ/9DQ0Bk0N34frGoc+njioqgm7RKRdtVIoKet4lmbmhuAB929F7gR+LqZTXpvd9/k7n3u3tfT03P6rY1FPfTKdl6jXEREGgr0QWBlYruXySWV24BHANz9h0A3sLQZDUyTMau5KKqSi4hII4G+DVhrZmvMrJPooufmmmP2Ar8EYGaXEAX6mddU6rGaW//VQxcRqR/o7p4H7gC2AruIRrPsMLN7zeym+LDPAL9jZj8BHgI+5dM4fjBTM4euLoqKiECukYPcfQvRxc7kvrsTz3cCH2lu06ZmNT30qnHouigqIm0q3DtFE7k9rh66iEiogV7TQ1cNXUQkzEAHm3KBC3XQRaRdBRnoGYNkdE9oLhcRkVAD3UguUqQeuohIoIFeO8olOQ5dHXQRaVdBBno0H3pF8k5RddFFpF0FGeiTeuh5jXIREQk20KvmQ0/O5aIuuoi0qSADPbqxKH0cumroItKuggz02kWiq2ZbnPnmiIicE4IM9NqLotWjXBTpItKeggz0SZNzaRy6iEiogV5TQy9qlIuISJCBXrsE3Xhesy2KiAQa6Kb50EVEagQZ6MCUsy0qz0WkXQUZ6LULXFSNcpmF9oiInAsaCnQzW29mu81swMzunOKYf2tmO81sh5n93+Y2s/azqLkoqhq6iEjdNUXNLAvcB1wHDALbzGxzvI5o6Zi1wF3AR9z9iJktm64Gw6nHoYuItKtGeuhXAgPuvsfdx4GHgZtrjvkd4D53PwLg7geb28xqtUvQVZdc1EUXkfbUSKCvAPYltgfjfUnvBd5rZv9kZs+a2fpmNTCVnWIJOuW5iLSpuiUXoqlTatXGZg5YC1wN9ALfN7NL3f1o1RuZbQQ2Aqxateq0G1uSqamhT2guFxGRhnrog8DKxHYvsD/lmO+4+4S7vwbsJgr4Ku6+yd373L2vp6fnTNs8aZRLXnO5iIg0FOjbgLVmtsbMOoFbgc01xzwGXANgZkuJSjB7mtnQpGi2xSnmclGei0ibqhvo7p4H7gC2AruAR9x9h5nda2Y3xYdtBQ6b2U7gKeAP3f3wtDW6dhy65nIREWmoho67bwG21Oy7O/HcgT+If6bdqWZbFBFpV0HeKTppCbpCkUx86VYlFxFpV0EGenRjUXIcutORjU5F49BFpF0FGehRyaWynS8W6czFga48F5E2FWSgT5o+t+B0lnvoIiLtKdxAL1bf+p/Lpt3/JCLSPoIM9GzGKNTMtliuoavmIiJtKshAz5hRujm0WHQKRZVcRESCDPRshnLJpXRTUaWHPmvNEhGZVYEGeqXkUrqpqDTKRX10EWlXQQZ68qJoKdA74oui6qGLSLsKMtBziR56qeSSywZ5KiIiTRNkCmYyVu6Zl0suuigqIm0uyEDPJm4sKi0/p5KLiLS7MAM9YxSKtYGuuVxEpL0FGeiZTKWHno+DvUNzuYhImwsy0LM2uYfepXHoItLmwgz0RMmldFFUc7mISLsLMtCj2Raj5/naO0VVQxeRNhVkoOeyVg7yifKNRSq5iEh7ayjQzWy9me02swEzu/MUx91iZm5mfc1r4mTRnaLR88m3/ouItKe6KWhmWeA+4AZgHbDBzNalHLcA+D3guWY3slY2Q+VOUY1DFxEBGuuhXwkMuPsedx8HHgZuTjnuz4G/AEab2L5UaaNcOrNZQDV0EWlfjQT6CmBfYnsw3ldmZpcDK9398VO9kZltNLN+M+sfGho67caWZDJRb7xY9PI4dI1yEZF210igpyVluRtsZhngC8Bn6r2Ru29y9z537+vp6Wm8lTWyFjWp4J7ooeuiqIi0t0YCfRBYmdjuBfYnthcAlwJPm9nrwFXA5um8MFrqoReKPnn63On6UBGRc1wjgb4NWGtma8ysE7gV2Fx60d2PuftSd1/t7quBZ4Gb3L1/WlpMNH0uxIFeGodevvVfkS4i7aluoLt7HrgD2ArsAh5x9x1mdq+Z3TTdDUyTzVRKLuO149Bno0EiIueAXCMHufsWYEvNvrunOPbqs2/WqWUscVFUNXQRESDQO0WzqTX0IE9FRKRpgkzBTKLkMlGsvrGotujy0I/2cvd3tqu2LiItL8hAz5ZLLolFoqeYD/2uR3/K1374BsfH8jPaRhGRmRZmoMetLnilhl4a+ZLM82KxsqX+uYi0ukADPWp2oeBMFJ2OrGFMnsvl8Mh4+bkXZ7SJIiIzLtBAjx4L7kzki3RkM8RVmKpa+ZETlUAvqoYuIi0uyEAvDVssxHO55DKWOj/BOyMKdBFpH0EGemnYYjGeyyU5ZDEZ20eqAn2mWiciMjvCDHSrHoeey1p5CrFkR/zYyYnycw1bFJFWF2SgJyfnmigWyWUylYuiiT56cqiieugi0uqCDPTyOHSPeugdWStfFE3WXIZHk4GuRBeR1hZmoGcTPfRCkVw2Q9p9oskeuuJcRFpdmIFuyUB3OrKZqvldSo4ne+iquYhIiwsz0BPhPV4o0pnLkItHupTmR4eaHrryXERaXJCBnkkuQZcv0pXNlG/9nyhUknt4TDV0EWkfQQZ6eRx6EcYLRTpyVh6Lni8kSy6VYYsKdBFpdYEGevRYcGc8X6Qzm4nGojN1yUUldBFpdUEGenLFotKdoh3xhF1VJZfRPHM6soBuLBKR1tdQoJvZejPbbWYDZnZnyut/YGY7zexFM3vCzN7d/KZW5EqzLRbjHnouQ0euVENP9NBH8yycE62ypx66iLS6uoFuZlngPuAGYB2wwczW1Rz2AtDn7pcB3wb+otkNTYrznHxplEs2Uw750vzoxaJzfDzPgu6OaFs9dBFpcY300K8EBtx9j7uPAw8DNycPcPen3P1EvPks0NvcZlZLTs5V7qFnq0e5nJgo4A6L5ijQRaQ9NBLoK4B9ie3BeN9UbgP+Lu0FM9toZv1m1j80NNR4K2tU31iUPg69dFPRwu6o5KI8F5FW10igp001nhqPZvYbQB/wl2mvu/smd+9z976enp7GW1kjU9ND70gZh358LBqyuDDuoSvQRaTV5Ro4ZhBYmdjuBfbXHmRm1wJ/AnzU3cea07x0yR566U7R2nHow+UeukouItIeGumhbwPWmtkaM+sEbgU2Jw8ws8uBrwI3ufvB5jezWqmGnq+Zy8UsUXKJx6BXRrko0EWktdUNdHfPA3cAW4FdwCPuvsPM7jWzm+LD/hKYD3zLzH5sZpuneLumKAX66EQBgK5cdBodmUyl5DKphz6dLRIRmX2NlFxw9y3Alpp9dyeeX9vkdp1SZxzgI2NRoJdGuOSyVh62OFzuoZdq6Ep0EWltQd4pWqqXj8Sh3Rlvd2QzjBdqR7mohy4i7SHIQC8FeKlO3pmLbu/v7sgwnq+uoS/oTq+hb3/zGP/4yqEZaa+IyExoqORyrqmUXKLQLpVcunLZcl39+Fie7o7K6JdkoE8UivzK//pHAF74r9exeF7njLVdRGS6BNlDz2aMjMHIeKmHHp1Gd0eGsbiHPjyaZ35XB/H106px6C8OHis/PzwyPjONFhGZZkEGOkT18uPxRdFSCaa2h76gO1e+CSkZ6K+8PVx+XlBxXURaRLCB3pnLVC6K5kqBXumhj4zlmd+VK/fQkyWX1w6NlJ8nZ2cUEQlZuIGezSRq6KWSS6KHPhoFulllmoCSPYlAVw9dRFpFuIGeyyRGuUzuoQ+P5ZnfnSsvhpEsubx2aKS88EVegS4iLSLYQO+o00MfHp1ILbkUis7ewydYu3w+UJk/XUQkdAEHunHsZDSjYqm33dWRYXQiCuhjJyZYNKejslxd3BHff/Qk44Ui71kWBbpKLiLSKoIN9M5cthzSczujQJ/flWNkPM94vsjwWJ7z53ViNT30Uv187bIFgEouItI6gg30OR2VpicD/fhoniMnorHli+d1JmroUXC/NnQcgLVxD700O2PJC3uP8MLeI9PbeBGRaRDknaIAczsrTZ8TB/q8rhz5orP/6EmAmh569PjaoREWdOW4YFE3UJk/HeCng8f4tft/AMD3/+gaVi6ZO92nISLSNOH20OMQh0oNvTRvy953ouVNkz30ZMllTc88ctnKIhklX/vh6+Xnbxw+gYhISIIN9FKZpTNbWU90flcU6PviQD9/XuekW/8HDh7noqXzKkvWxYE+li/w9zsOcPHyqLZeGi0jIhKK4AM92VMvTZW7Zyi68LlkXmfVjUVHT4zz1rFRLrlwIblMdOqFuIb+9O4hhkfzfLyvF4CTNYE+cPA4b8alHBGRc1GwgT6nI+qNl5aYA+hZ0AXASweGyRgsmtNRDv7h0TwvHYjmcHnfhQvLqx6VVjh67IU3OX9eJ9deshyoDvRH+vdx7ef/H9d87umqeWBERM4lwQb6vK4oqBfFKxIBLI0DfedbP+PCRXPIZTMsW9BNR9Z48+hJfhrPsnjJBQuqaujHTkzwxK6D/OsPvIv5cR2+VHLZsf8Yf/rYdlYtmct4vsgLe4+WP69YdJ7bc5iXFfIicg5oKNDNbL2Z7TazATO7M+X1LjP7Zvz6c2a2utkNrVXqjSdHHS6dXxnV0rt4DhBNtbvivDm8fmiE7w8c4j3L5rNsYXe55JIvOg9t28t4ocgtV/SWL7CeHC9wZGSc//B/nmfx3A6+cfuHADg0MgZEo2Vu3fQsv77pWT72hWd46qXK2tgnxvN8/5UhXth7REvficiMqTts0cyywH3AdcAgsM3MNrv7zsRhtwFH3P09ZnYr8Fng16ejwSXLFkTDDscTt+535bL0Lp7DvndOcvEFC8r7L+s9j+/tfJuCO5/40CqA8kXRlw8M89iP3+Sj7+3h0hWLyqNe/mHX2zz6z2/y9rExvvnvr2Llkrl05TI8/KN9vHV0lG/276M7l+Hem9/P3d/Zwee/9zKHR8Z55uUhvrvzQPmO1f949c9x3brlHDg2yqtDx9kzNMLxsTy3XNHLZb3ncXxsgkPHxzl0fIyT4wX6Vi9h5eI5jIwXGB6d4OR4gfFCkZVL5pavEUA0rn6i4GQzVi4fiUh7a2Qc+pXAgLvvATCzh4GbgWSg3wz8Wfz828D/NjPzaeyelnrgN156QdX+tcsWsO+dk1y5Zkl533XrlrP5J/sBuOWK6KJnaUKvrz/7BovndvDff/VSgHI4bnv9CMsXdvHXn+rj8lWLAVh9/jx2vz3MN7ft46affxd/eP3FLF/YzdYdB/ingcP8l2/9hEVzOvg3H+zl+vdfwOe+u5v7n36V+59+tdyWdy3qZngsz3d3vn1a52sGHeXfKorlcfWd2QzdHRkcwKOLv0WP/sGa25XFqB/2ZpSHd5rFP1S2gfK7lC4yl991Bv4tmYl/rkrnJTITbv2Fldz+ry5q+vtavcw1s1uA9e5+e7z9m8CH3P2OxDHb42MG4+1X42MO1bzXRmAjwKpVq6544403zqrxLx34GRcvX1D1P+PQ8BhPvvQ2H79iZXlxi2LR+caP9rJsQRfXv7/yD8Aj/ft44/AIG65cRe/iyk1ET770NqMTRX7xfcvo7shWvfeBY6P83LJ5VTc2HR/LM3DwOAu6c7x7ydzyMMpjJyb4571HKLqzfGE3a5bOY15XjqMnxvmHXQcZnSiwoDvH0vldLJ3fRaHo/ODVQ5wYLzC3M8vC7g7mdmXJmjFw8Dgj41FdP5cxclkjlzGGx/KMxb8NmEHWjEzGmCgUOTFWf+il47iDE4/Vj59D5e7ayjY129NfTpqRgpWqYjLDrlu3nF+9fMUZ/bdm9ry796W+1kCgfxy4vibQr3T3TyeO2REfkwz0K9398FTv29fX5/39/ad9MiIi7exUgd7IRdFBYGViuxfYP9UxZpYDFgHvnH5TRUTkTDUS6NuAtWa2xsw6gVuBzTXHbAY+GT+/BXhyOuvnIiIyWd2Lou6eN7M7gK1AFnjA3XeY2b1Av7tvBv4a+LqZDRD1zG+dzkaLiMhkDc226O5bgC01++5OPB8FPt7cpomIyOkI9k5RERGppkAXEWkRCnQRkRahQBcRaRF1byyatg82GwLO9FbRpcChuke1Fp1ze9A5t4ezOed3u3tP2guzFuhnw8z6p7pTqlXpnNuDzrk9TNc5q+QiItIiFOgiIi0i1EDfNNsNmAU65/agc24P03LOQdbQRURkslB76CIiUkOBLiLSIoIL9HoLVofKzFaa2VNmtsvMdpjZ78f7l5jZ98zslfhxcbzfzOxL8Z/Di2b2wdk9gzNjZlkze8HMHo+318QLjb8SLzzeGe+f8YXIp4uZnWdm3zazl+Lv+8Ot/D2b2X+O/05vN7OHzKy7Fb9nM3vAzA7GK7iV9p3292pmn4yPf8XMPpn2WVMJKtATC1bfAKwDNpjZutltVdPkgc+4+yXAVcDvxud2J/CEu68Fnoi3IfozWBv/bAS+PPNNborfB3Yltj8LfCE+3yNEC5BDYiFy4AvxcaH6n8Dfu/v7gA8QnX9Lfs9mtgL4PaDP3S8lmoK7tJB8q33PDwLra/ad1vdqZkuAe4APEa3nfE/pH4GGuHswP8CHga2J7buAu2a7XdN0rt8BrgN2AxfG+y4EdsfPvwpsSBxfPi6UH6LVr54AfhF4nGg96ENArvb7JpqP/8Px81x8nM32OZzBOS8EXqtte6t+z8AKYB+wJP7eHgeub9XvGVgNbD/T7xXYAHw1sb/quHo/QfXQqfzlKBmM97WU+NfMy4HngOXu/hZA/LgsPqwV/iy+CPwRUIy3zweOuns+3k6eU/l849ePxceH5iJgCPibuNT0V2Y2jxb9nt39TeBzwF7gLaLv7Xla/3suOd3v9ay+79AC3VL2tdS4SzObD/wt8J/c/WenOjRlXzB/Fmb2K8BBd38+uTvlUG/gtZDkgA8CX3b3y4ERKr+Gpwn6vONywc3AGuBdwDyickOtVvue65nqPM/q/EML9EYWrA6WmXUQhfk33P3RePfbZnZh/PqFwMF4f+h/Fh8BbjKz14GHicouXwTOixcah+pzapWFyAeBQXd/Lt7+NlHAt+r3fC3wmrsPufsE8CjwL2j977nkdL/Xs/q+Qwv0RhasDpKZGdHarLvc/fOJl5ILcH+SqLZe2v9b8dXyq4BjpV/tQuDud7l7r7uvJvoen3T3TwBPES00DpPPN/iFyN39ALDPzC6Od/0SsJMW/Z6JSi1Xmdnc+O946Xxb+ntOON3vdSvwMTNbHP9287F4X2Nm+yLCGVx0uBF4GXgV+JPZbk8Tz+tfEv1q9SLw4/jnRqL64RPAK/Hjkvh4Ixrx8yrwU6JRBLN+Hmd47lcDj8fPLwJ+BAwA3wK64v3d8fZA/PpFs93uszjfnwf64+/6MWBxK3/PwH8DXgK2A18HulrxewYeIrpOMEHU077tTL5X4N/F5z8A/PbptEG3/ouItIjQSi4iIjIFBbqISItQoIuItAgFuohIi1Cgi4i0CAW6iEiLUKCLiLSI/w+YPSDU4oaoZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4974, -1.4974, -1.6550, -1.6550]) tensor([-1.3398, -1.3398])\n",
      "tensor([-1.3398, -1.3398, -1.4974, -1.4974]) tensor([-1.1822, -1.1822])\n",
      "tensor([-1.1822, -1.1822, -1.3398, -1.3398]) tensor([-1.0245, -1.0245])\n",
      "tensor([-1.0245, -1.0245, -1.1822, -1.1822]) tensor([-0.8669, -0.8669])\n",
      "tensor([-0.8669, -0.8669, -1.0245, -1.0245]) tensor([-0.7093, -0.7093])\n",
      "tensor([-0.7093, -0.7093, -0.8669, -0.8669]) tensor([-0.5517, -0.5517])\n",
      "tensor([-0.5517, -0.5517, -0.7093, -0.7093]) tensor([-0.3941, -0.3941])\n",
      "tensor([-0.3941, -0.3941, -0.5517, -0.5517]) tensor([-0.2364, -0.2364])\n",
      "tensor([-0.2364, -0.2364, -0.3941, -0.3941]) tensor([-0.0788, -0.0788])\n",
      "tensor([-0.0788, -0.0788, -0.2364, -0.2364]) tensor([0.0788, 0.0788])\n",
      "tensor([ 0.0788,  0.0788, -0.0788, -0.0788]) tensor([0.2364, 0.2364])\n",
      "tensor([0.2364, 0.2364, 0.0788, 0.0788]) tensor([0.3941, 0.3941])\n",
      "tensor([0.3941, 0.3941, 0.2364, 0.2364]) tensor([0.5517, 0.5517])\n",
      "tensor([0.5517, 0.5517, 0.3941, 0.3941]) tensor([0.7093, 0.7093])\n",
      "tensor([0.7093, 0.7093, 0.5517, 0.5517]) tensor([0.8669, 0.8669])\n",
      "tensor([0.8669, 0.8669, 0.7093, 0.7093]) tensor([1.0245, 1.0245])\n",
      "tensor([1.0245, 1.0245, 0.8669, 0.8669]) tensor([1.1822, 1.1822])\n",
      "tensor([1.1822, 1.1822, 1.0245, 1.0245]) tensor([1.3398, 1.3398])\n",
      "tensor([1.3398, 1.3398, 1.1822, 1.1822]) tensor([1.4974, 1.4974])\n",
      "tensor([1.4974, 1.4974, 1.3398, 1.3398]) tensor([1.6550, 1.6550])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(my_data)):\n",
    "    print(my_data.x[i],my_data.y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  tensor([[-1.4974, -1.4974, -1.6550, -1.6550]])\n",
      "yhat:  tensor([[-1.3398, -1.3398]])\n",
      "x:  tensor([[-1.3398, -1.3398, -1.4974, -1.4974]])\n",
      "yhat:  tensor([[-1.1822, -1.1822]])\n",
      "x:  tensor([[-1.1822, -1.1822, -1.3398, -1.3398]])\n",
      "yhat:  tensor([[-1.0246, -1.0246]])\n",
      "x:  tensor([[-1.0245, -1.0245, -1.1822, -1.1822]])\n",
      "yhat:  tensor([[-0.8669, -0.8669]])\n",
      "x:  tensor([[-0.8669, -0.8669, -1.0245, -1.0245]])\n",
      "yhat:  tensor([[-0.7093, -0.7093]])\n",
      "x:  tensor([[-0.7093, -0.7093, -0.8669, -0.8669]])\n",
      "yhat:  tensor([[-0.5517, -0.5517]])\n",
      "x:  tensor([[-0.5517, -0.5517, -0.7093, -0.7093]])\n",
      "yhat:  tensor([[-0.3941, -0.3941]])\n",
      "x:  tensor([[-0.3941, -0.3941, -0.5517, -0.5517]])\n",
      "yhat:  tensor([[-0.2364, -0.2364]])\n",
      "x:  tensor([[-0.2364, -0.2364, -0.3941, -0.3941]])\n",
      "yhat:  tensor([[-0.0788, -0.0788]])\n",
      "x:  tensor([[-0.0788, -0.0788, -0.2364, -0.2364]])\n",
      "yhat:  tensor([[0.0788, 0.0788]])\n",
      "x:  tensor([[ 0.0788,  0.0788, -0.0788, -0.0788]])\n",
      "yhat:  tensor([[0.2364, 0.2364]])\n",
      "x:  tensor([[0.2364, 0.2364, 0.0788, 0.0788]])\n",
      "yhat:  tensor([[0.3940, 0.3940]])\n",
      "x:  tensor([[0.3941, 0.3941, 0.2364, 0.2364]])\n",
      "yhat:  tensor([[0.5517, 0.5517]])\n",
      "x:  tensor([[0.5517, 0.5517, 0.3941, 0.3941]])\n",
      "yhat:  tensor([[0.7093, 0.7093]])\n",
      "x:  tensor([[0.7093, 0.7093, 0.5517, 0.5517]])\n",
      "yhat:  tensor([[0.8669, 0.8669]])\n",
      "x:  tensor([[0.8669, 0.8669, 0.7093, 0.7093]])\n",
      "yhat:  tensor([[1.0245, 1.0245]])\n",
      "x:  tensor([[1.0245, 1.0245, 0.8669, 0.8669]])\n",
      "yhat:  tensor([[1.1822, 1.1822]])\n",
      "x:  tensor([[1.1822, 1.1822, 1.0245, 1.0245]])\n",
      "yhat:  tensor([[1.3398, 1.3398]])\n",
      "x:  tensor([[1.3398, 1.3398, 1.1822, 1.1822]])\n",
      "yhat:  tensor([[1.4974, 1.4974]])\n",
      "x:  tensor([[1.4974, 1.4974, 1.3398, 1.3398]])\n",
      "yhat:  tensor([[1.6550, 1.6550]])\n"
     ]
    }
   ],
   "source": [
    "for x,y in trainloader:\n",
    "        yhat = model(x)\n",
    "        print('x: ',x.data)\n",
    "        print('yhat: ',yhat.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1 3. ]\n",
      "[0.31 0.3 ]\n",
      "[3.23125267 3.07363058]\n",
      "[3.23125258 3.07363049]\n",
      "tensor([[3.1000, 3.0000]])\n"
     ]
    }
   ],
   "source": [
    "query_dim1 = np.array([3.1,3.0])\n",
    "query_dim2 = np.array([0.31,0.3])\n",
    "print(query_dim1)\n",
    "print(query_dim2)\n",
    "\n",
    "scaled_query_dim1 = (query_dim1 - dim1_mean)/dim1_std\n",
    "scaled_query_dim2 = (query_dim2 - dim2_mean)/dim2_std\n",
    "print(scaled_query_dim1)\n",
    "print(scaled_query_dim2)\n",
    "\n",
    "new_query = Variable(torch.Tensor([query_dim1]))\n",
    "print(new_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new_var = Variable(torch.Tensor([[3.1,3.0],[0.31,0.3]])) #this is grouped differently, make it consistent (TODO)\n",
    "# new_var = Variable(torch.Tensor([3.1,0.31,3.0,0.3]))\n",
    "# print(new_var[:][0])\n",
    "# print('true new_var:\\n',new_var)\n",
    "\n",
    "# new_var[0][:] = (new_var[0][:] - dim1_mean) /  dim1_std\n",
    "# new_var[1][:] = (new_var[1][:] - dim2_mean) /  dim2_std\n",
    "\n",
    "# # new_var[0][:] = (new_var[0][:] - dim1_mean) /  dim1_std\n",
    "# # new_var[1][:] = (new_var[1][:] - dim2_mean) /  dim2_std\n",
    "\n",
    "# print('scaled new_var:\\n',new_var)\n",
    "\n",
    "# new_var = new_var.view(-1,4)\n",
    "\n",
    "# answer = model(new_var)\n",
    "\n",
    "# print('\\n raw answer:\\n',answer)\n",
    "# print('\\n scaled up again:\\n')\n",
    "# print(answer[0][0]*dim1_std + dim1_mean)\n",
    "# print(answer[0][1]*dim2_std + dim2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1359, 0.3681]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = torch.arange(0,2.2,0.1)\n",
    "y_data = torch.arange(0,0.22,0.01)\n",
    "\n",
    "mean_x_data = x_data.mean(0, keepdim=True)\n",
    "std_x_data = x_data.std(0, unbiased=False, keepdim=True)\n",
    "x_data -= mean_x_data\n",
    "x_data /= std_x_data\n",
    "\n",
    "mean_y_data = y_data.mean(0, keepdim=True)\n",
    "std_y_data = y_data.std(0, unbiased=False, keepdim=True)\n",
    "y_data -= mean_y_data\n",
    "y_data /= std_y_data\n",
    "\n",
    "new_var = Variable(torch.Tensor([[3.1,0.31,3.0,0.3]]))\n",
    "model(new_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.Tensor([3.1,0.31,3.0,0.3])\n",
    "# tmp *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2313, 3.2313, 3.0736, 3.0736]])\n",
      "tensor([[3.3889, 3.3889]], grad_fn=<AddmmBackward>)\n",
      "tensor([3.2000], grad_fn=<AddBackward0>)\n",
      "tensor([0.3200], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = 3.1\n",
    "y1 = 0.31\n",
    "x2 = 3.0\n",
    "y2 = 0.3\n",
    "\n",
    "x1 -= mean_x_data\n",
    "x1 /= std_x_data\n",
    "x2 -= mean_x_data\n",
    "x2 /= std_x_data\n",
    "\n",
    "y1 -= mean_y_data\n",
    "y1 /= std_y_data\n",
    "y2 -= mean_y_data\n",
    "y2 /= std_y_data\n",
    "\n",
    "new_var = Variable(torch.Tensor([[x1,y1,x2,y2]]))\n",
    "answer = model(new_var)\n",
    "\n",
    "print(new_var)\n",
    "print(answer)\n",
    "\n",
    "x_ans = answer[0][0] * std_x_data\n",
    "x_ans = x_ans + mean_x_data\n",
    "y_ans = answer[0][1] * std_y_data\n",
    "y_ans = y_ans + mean_y_data\n",
    "\n",
    "print(x_ans)\n",
    "print(y_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.1 3. ]\n",
      "[0.31 0.3 ]\n",
      "[3.23125267 3.07363058]\n",
      "[3.23125258 3.07363049]\n",
      "tensor([[3.2313, 3.2313, 3.0736, 3.0736]])\n",
      "\n",
      " raw answer:\n",
      " tensor([[3.3889, 3.3889]], grad_fn=<AddmmBackward>)\n",
      "\n",
      " scaled up again:\n",
      "\n",
      "tensor(3.2000, grad_fn=<AddBackward0>)\n",
      "tensor(0.3200, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "query_dim1 = np.array([3.1,3.0])\n",
    "query_dim2 = np.array([0.31,0.3])\n",
    "print(query_dim1)\n",
    "print(query_dim2)\n",
    "\n",
    "scaled_query_dim1 = (query_dim1 - dim1_mean)/dim1_std\n",
    "scaled_query_dim2 = (query_dim2 - dim2_mean)/dim2_std\n",
    "print(scaled_query_dim1)\n",
    "print(scaled_query_dim2)\n",
    "\n",
    "# Build combination so x and y are adjacent for 1 pose\n",
    "c = np.empty((scaled_query_dim1.size + scaled_query_dim2.size,))\n",
    "c[0::2] = scaled_query_dim1\n",
    "c[1::2] = scaled_query_dim2\n",
    "\n",
    "new_query = Variable(torch.Tensor([c]))\n",
    "print(new_query)\n",
    "\n",
    "answer = model(new_query)\n",
    "print('\\n raw answer:\\n',answer)\n",
    "print('\\n scaled up again:\\n')\n",
    "print(answer[0][0]*dim1_std + dim1_mean)\n",
    "print(answer[0][1]*dim2_std + dim2_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
